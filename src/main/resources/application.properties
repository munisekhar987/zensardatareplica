# CDC Consumer Application Configuration

# Server Configuration
server.port=9095
spring.application.name=CDC-DataReplicationAPP

# Kafka Configuration
# Kafka Bootstrap Server
# Google Cloud Managed Kafka Bootstrap Server
spring.kafka.bootstrap-servers=bootstrap.transapp-rollback-poc.us-east4.managedkafka.pr-transapp-dev-use4-01.cloud.goog:9092

# Consumer Configuration
spring.kafka.consumer.group-id=multi-cdc-consumer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

# Google Cloud Managed Kafka Security Configuration (from official docs)
spring.kafka.properties.security.protocol=SASL_SSL
spring.kafka.properties.sasl.mechanism=OAUTHBEARER
spring.kafka.properties.sasl.login.callback.handler.class=com.google.cloud.hosted.kafka.auth.GcpLoginCallbackHandler
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;
# Additional OAuth Configuration
spring.kafka.properties.sasl.oauthbearer.token.endpoint.url=https://oauth2.googleapis.com/token

# CDC Topic Configuration
# Comma-separated list of Kafka topics to consume from
cdc.kafka.topics=mytest.public.poctest

# Topic to Table Mappings Configuration
# Format: Topic name -> Table name
cdc.topic.table-mappings={'mypg.public.handoff_batchroute': 'HANDOFF_BATCHROUTE',\
  'mypg.public.handoff_batchstop' : 'HANDOFF_BATCHSTOP' ,\
  'mypg.public.deliveryconfirm' : 'DELIVERYCONFIRM' ,\
  'mypg.public.dispatch' : 'DISPATCH'}

# Primary Key Configuration for Tables
# Format: Table name -> comma-separated list of primary key column names
cdc.table.primary-keys={'HANDOFF_BATCHROUTE': 'BATCH_ID' , 'HANDOFF_BATCHSTOP' : 'BATCH_ID,WEBORDER_ID' ,'DISPATCH' : 'DISPATCH_ID'}

# Tables that allow duplicates (no primary key or unique constraint)
# For tables where duplicates are allowed or no primary key constraint exists
cdc.tables.allow-duplicates=DELIVERYCONFIRM



# Duplicate Handling Strategy
# Options: merge, upsert, ignore, none
# merge - Uses Oracle's MERGE statement to handle duplicates (recommended)
# upsert - Try update first, if not exists then insert
# ignore - Check if record exists first, only insert if not found
# none - Standard insert (will fail on duplicates)
cdc.handle.duplicates=merge

# Oracle Database Connection Configuration
#oracle.db.url=jdbc:oracle:thin:@localhost:1521/XEPDB1
#oracle.db.username=system
#oracle.db.password=admin
#oracle.db.schema=SYSTEM

oracle.db.url=jdbc:oracle:thin:@10.64.45.111:1521/devint
oracle.db.username=dlv
oracle.db.password=dlv
oracle.db.schema=DLV

# PostgreSQL Source Configuration (for UDT support)
#postgres.db.url=jdbc:postgresql://localhost:5432/postgres
#postgres.db.username=postgres
#postgres.db.password=mysecretpassword
#postgres.db.schema=public

postgres.db.url=jdbc:postgresql://10.52.3.6:5432/psqldev
postgres.db.username=replication_user
postgres.db.password=Welcome@12345
postgres.db.schema=transp


# Tables with UDT columns that need supplementary fetching
# Format: table_name:primary_key_column
postgres.udt.tables=HANDOFF_BATCHROUTE:BATCH_ID

# UDT Type Mapping Configuration - FIXED FORMAT FOR SPRING SPEL
# The format must use proper SpEL expression with map notation
postgres.udt.type-mapping={'handoff_routing_route_no':'HANDOFF_ROUTING_ROUTE_NO', 'handoff_roadnet_route_no':'HANDOFF_ROADNET_ROUTE_NO'}

# UDT Column Mapping Configuration - FIXED FORMAT FOR SPRING SPEL
# The format must use proper SpEL expression with map notation
postgres.udt.column-mapping={'HANDOFF_BATCHROUTE.ROUTING_ROUTE_NO':'handoff_routing_route_no', 'HANDOFF_BATCHROUTE.ROADNET_ROUTE_NO':'handoff_roadnet_route_no'}

# Logging Configuration
logging.level.com.zensar.data.replication=INFO
logging.level.com.zensar.data.replication.consumer=DEBUG
logging.level.com.zensar.data.replication.service=DEBUG
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss.SSS} %highlight(%-5level) %cyan(%-40logger{40}) : %msg%n